{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a80e961cdf3a4ea29cd91f5ddb0c6c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a1fecbc8a740679324ad3924af01c4",
              "IPY_MODEL_e4b8dc67bad0482d84cad1724e88dd87",
              "IPY_MODEL_7942a1c2f34541c0829209f2afb61964"
            ],
            "layout": "IPY_MODEL_d1f8e89ee46b4141bc2186b5a68607bf"
          }
        },
        "f4a1fecbc8a740679324ad3924af01c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0215d57f80794e9ebbcebac0d3326977",
            "placeholder": "​",
            "style": "IPY_MODEL_b690e6f7745b4be387228ddafffea9d3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e4b8dc67bad0482d84cad1724e88dd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752476eafd744c068f8fcf1da0bcbab1",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da1e37a101504c74b433c286e3823817",
            "value": 3
          }
        },
        "7942a1c2f34541c0829209f2afb61964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a352f6f0a36d4e5197a5e0d4dd152dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_8e7404ee6bcb4cf6bddb7419a1818246",
            "value": " 3/3 [00:52&lt;00:00, 15.52s/it]"
          }
        },
        "d1f8e89ee46b4141bc2186b5a68607bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0215d57f80794e9ebbcebac0d3326977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b690e6f7745b4be387228ddafffea9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "752476eafd744c068f8fcf1da0bcbab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1e37a101504c74b433c286e3823817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a352f6f0a36d4e5197a5e0d4dd152dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7404ee6bcb4cf6bddb7419a1818246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFqfNJojeN-q",
        "outputId": "65f43e8d-d498-4b98-935d-713131a9917d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: vptq in /usr/local/lib/python3.11/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from vptq) (2.5.1+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from vptq) (3.3.0)\n",
            "Requirement already satisfied: transformers>=4.45 in /usr/local/lib/python3.11/dist-packages (from vptq) (4.49.0.dev0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from vptq) (0.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vptq) (5.9.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from vptq) (1.3.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from vptq) (5.16.0)\n",
            "Requirement already satisfied: plotly==5.9.0 in /usr/local/lib/python3.11/dist-packages (from vptq) (5.9.0)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from vptq) (12.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vptq) (4.67.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from vptq) (3.4.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly==5.9.0->vptq) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->vptq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->vptq) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45->vptq) (0.21.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->vptq) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->vptq) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->vptq) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->vptq) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->vptq) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->vptq) (3.11.12)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.28.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.9.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->vptq) (0.34.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio->vptq) (14.2)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->vptq) (12.570.86)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->vptq) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->vptq) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->vptq) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->vptq) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->vptq) (1.18.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->vptq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->vptq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->vptq) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->vptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->vptq) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->vptq) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->vptq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio->vptq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.45->vptq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.45->vptq) (2.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->vptq) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->vptq) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->vptq) (13.9.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers->vptq) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers->vptq) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->vptq) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->vptq) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->vptq) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->vptq) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/huggingface/transformers.git -U\n",
        "! pip install vptq -U\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u1n5a2xAi5EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nraZWNF3phm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIj2lb8hphjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yw6yEY3NphgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yk8ZBTSaphaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "65Hu_-kdphIW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6IsPYGOpiN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUNUhfC-piL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBCzwN85piJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y7UKLO37piGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSmy_FlDph-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qwen2.5-32B"
      ],
      "metadata": {
        "id": "brHnJl5dpiw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load VPTQ-quantized model directly from HuggingFace Hub\n",
        "model = AutoModelForCausalLM.from_pretrained(\"VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft\", device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft\")\n",
        "\n",
        "# Simple inference\n",
        "prompt = \"Explain: Do not go gentle into that good night.\"\n",
        "output = model.generate(**tokenizer(prompt, return_tensors=\"pt\").to(model.device))\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "m3gW1nvjiiVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load VPTQ-quantized model directly from HuggingFace Hub\n",
        "model = AutoModelForCausalLM.from_pretrained(\"VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft\", device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "a80e961cdf3a4ea29cd91f5ddb0c6c0f",
            "f4a1fecbc8a740679324ad3924af01c4",
            "e4b8dc67bad0482d84cad1724e88dd87",
            "7942a1c2f34541c0829209f2afb61964",
            "d1f8e89ee46b4141bc2186b5a68607bf",
            "0215d57f80794e9ebbcebac0d3326977",
            "b690e6f7745b4be387228ddafffea9d3",
            "752476eafd744c068f8fcf1da0bcbab1",
            "da1e37a101504c74b433c286e3823817",
            "a352f6f0a36d4e5197a5e0d4dd152dfa",
            "8e7404ee6bcb4cf6bddb7419a1818246"
          ]
        },
        "id": "B6RdyR5AoQBY",
        "outputId": "5928dad8-1f53-40bd-a92e-fdab1e7f0c73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded VPTQ CUDA kernels.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a80e961cdf3a4ea29cd91f5ddb0c6c0f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple inference\n",
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "output = model.generate(**tokenizer(prompt, return_tensors=\"pt\").to(model.device))\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfZuOKMekun_",
        "outputId": "477a693b-3aa1-4bf4-c941-5c93bdd8d954"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is Napoleon Bonaparte? Napoleon Bonaparte was a French military and political leader who rose to prominence during the French Revolution and\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Simple inference\n",
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "output = model.generate(**tokenizer(prompt, return_tensors=\"pt\").to(model.device), max_new_tokens=50, num_beams=2)  # Added parameters\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-Ms47JqYnOSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple inference\n",
        "prompt = \"Who is Napoleon Bonaparte?\"\n",
        "output = model.generate(**tokenizer(prompt, return_tensors=\"pt\").to(model.device), max_new_tokens=50, num_beams=2, do_sample=True)  # Added parameters\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX3rqelYneW5",
        "outputId": "d6d53a11-2f36-4b9f-de32-770005599486"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is Napoleon Bonaparte? Napoleon Bonaparte was a French military and political leader who rose to prominence during the French Revolution and led France as Emperor of the French from 1804 to 1814. Born on August 15, 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple inference\n",
        "prompt = \"write python code for print number 4 six times\"\n",
        "output = model.generate(**tokenizer(prompt, return_tensors=\"pt\").to(model.device), max_new_tokens=50, num_beams=2, do_sample=True)  # Added parameters\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB2Vvy7ko_L4",
        "outputId": "9ac5ec19-e91d-432f-e5f8-cd3a7c215717"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write python code for print number 4 six times\n",
            "Certainly! Here is a Python code snippet that prints the number 4 six times:\n",
            "\n",
            "```python\n",
            "for i in range(6):\n",
            "    print(4)\n",
            "```\n",
            "\n",
            "This code will output:\n",
            "\n",
            "```\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "    print(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAhixnLmpVZA",
        "outputId": "a0d58bf3-b86a-4d86-b755-bf0850f9b9aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m vptq --model VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft --prompt \"hi\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvfweP4TlGOf",
        "outputId": "78acaa38-45cf-49c4-9ccc-6c833485c729"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-15 03:12:47.743585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739589167.806152    4960 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739589167.828408    4960 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 03:12:47.907584: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Successfully loaded VPTQ CUDA kernels.\n",
            "Namespace(model='VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft', tokenizer='', prompt='hi', chat=False, chat_system_prompt='you are a math teacher.')\n",
            "Replacing linear layers...: 100% 839/839 [00:00<00:00, 2324.03it/s]\n",
            "Fetching 14 files:   0% 0/14 [00:00<?, ?it/s]\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 13.2MB/s]\n",
            "Fetching 14 files:   7% 1/14 [00:00<00:02,  4.76it/s]\n",
            "README.md: 100% 967/967 [00:00<00:00, 7.39MB/s]\n",
            "Fetching 14 files: 100% 14/14 [00:00<00:00, 63.16it/s]\n",
            "hi0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m vptq -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gblv5cCtmB3Q",
        "outputId": "ca872636-a812-4ed3-950a-702b83cab0df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-15 03:15:09.481812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739589309.510278    5653 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739589309.520672    5653 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 03:15:09.553897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Successfully loaded VPTQ CUDA kernels.\n",
            "usage: __main__.py [-h] --model MODEL [--tokenizer TOKENIZER] [--prompt PROMPT] [--chat]\n",
            "                   [--chat-system-prompt CHAT_SYSTEM_PROMPT]\n",
            "\n",
            "run a quantized model.\n",
            "\n",
            "A typical usage is:\n",
            "    python -m vptq --model [model name]         --prompt \"Explain: Do Not Go Gentle into That Good Night\"\n",
            "        [--chat-system-prompt \"you are a math teacher.\"]\n",
            " \n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         float/float16 model to load, such as [mosaicml/mpt-7b]\n",
            "  --tokenizer TOKENIZER\n",
            "                        default same as [model]\n",
            "  --prompt PROMPT       prompt to start generation\n",
            "  --chat                chat with the model\n",
            "  --chat-system-prompt CHAT_SYSTEM_PROMPT\n",
            "                        system prompt for chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m vptq --model VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft --prompt \"who is pytho?\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry6LYdfbm0do",
        "outputId": "819c7ff9-2f4c-4623-f07e-fc44567a5488"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-15 03:20:36.287544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739589636.308549    7068 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739589636.314864    7068 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 03:20:36.335814: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Successfully loaded VPTQ CUDA kernels.\n",
            "usage: __main__.py [-h] --model MODEL [--tokenizer TOKENIZER] [--prompt PROMPT] [--chat]\n",
            "                   [--chat-system-prompt CHAT_SYSTEM_PROMPT]\n",
            "__main__.py: error: unrecognized arguments: --n 55\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!python -m vptq --model VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft --prompt \"who is pytho?\" --chat"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoPrqwO8p4s-",
        "outputId": "05aa1fd0-48d1-4240-a1c1-109fea7cc61a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-15 03:49:14.752524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739591354.773185   14691 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739591354.779310   14691 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 03:49:14.801770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Successfully loaded VPTQ CUDA kernels.\n",
            "Namespace(model='VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft', tokenizer='', prompt='who is pytho?', chat=True, chat_system_prompt='you are a math teacher.')\n",
            "Replacing linear layers...: 100% 839/839 [00:00<00:00, 1442.95it/s]\n",
            "Fetching 14 files: 100% 14/14 [00:00<00:00, 23191.25it/s]\n",
            "============================chat with the model============================\n",
            "Press 'exit' to quit\n",
            "You: hi\n",
            "assistant: Hello! How can I help you today with math? Do you have a specific topic or problem you'd like to discuss?\n",
            "You: object address  : 0x7908b3913ee0\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m vptq --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqobzWNgn8lX",
        "outputId": "1e095c72-1329-4cfe-d3f8-875c36992c25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-15 03:47:24.257207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739591244.277957   14205 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739591244.284262   14205 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-15 03:47:24.306240: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Successfully loaded VPTQ CUDA kernels.\n",
            "usage: __main__.py [-h] --model MODEL [--tokenizer TOKENIZER] [--prompt PROMPT] [--chat]\n",
            "                   [--chat-system-prompt CHAT_SYSTEM_PROMPT]\n",
            "\n",
            "run a quantized model.\n",
            "\n",
            "A typical usage is:\n",
            "    python -m vptq --model [model name]         --prompt \"Explain: Do Not Go Gentle into That Good Night\"\n",
            "        [--chat-system-prompt \"you are a math teacher.\"]\n",
            " \n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         float/float16 model to load, such as [mosaicml/mpt-7b]\n",
            "  --tokenizer TOKENIZER\n",
            "                        default same as [model]\n",
            "  --prompt PROMPT       prompt to start generation\n",
            "  --chat                chat with the model\n",
            "  --chat-system-prompt CHAT_SYSTEM_PROMPT\n",
            "                        system prompt for chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"VPTQ-community/Qwen2.5-32B-Instruct-v8-k65536-0-woft\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "prompt = \"who is pytho?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=11)\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "SH_O5caConiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8A2oM7PconeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VPTQ_Qwen2.5-32B"
      ],
      "metadata": {
        "id": "AcWLvsCIonau"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}